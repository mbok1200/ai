import os
from urllib import response
from dotenv import load_dotenv
from rag_engine import RAGEngine
from function_agent import FunctionAgent
from tools.google_search import GoogleSearchTool
from workflow import DialogueState, Workflow
from openai import OpenAI
from typing import Dict, Any, List

import workflow
load_dotenv(".env")

class AISystem:
    def __init__(self):
        self.rag_engine = RAGEngine(
            pinecone_index_name=os.getenv("PINECONE_INDEX_NAME", "streamlit")
        )
        self.function_agent = FunctionAgent()
        self.google_search = GoogleSearchTool()
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.workflow = Workflow(self.openai_client)
        self.state = self.workflow.state
    def process_query(self, user_query: str, mode: str = "hybrid") -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞ –æ–±—Ä–æ–±–∫–∏ –∑–∞–ø–∏—Ç—É –∑ —Ä–µ–∂–∏–º–∞–º–∏ —Ä–æ–±–æ—Ç–∏"""
        if not user_query.strip():
            return {
                'response': "‚ùì –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å –∑–∞–ø–∏—Ç",
                'source': 'System',
                'metadata': {}
            }
        
        # –õ–æ–≥—ñ–∫–∞ –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ä–µ–∂–∏–º—É
        if mode == "rag_only":
            return self._process_rag_only(user_query)
        elif mode == "web_only":
            return self._search_and_analyze_web(user_query)
        elif mode == "research":
            return self._research_mode(user_query)
        else:  # hybrid (default)
            return self._process_hybrid(user_query)
    
    def _process_rag_only(self, user_query: str) -> Dict[str, Any]:
        try:
            response = self.workflow.process_user_input("—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ —Å—å–æ–≥–æ–¥–Ω—ñ")
            print(response)
            return {}
        except Exception as e:
            print(f"Function calling –ø–æ–º–∏–ª–∫–∞: {e}")

        # 2. RAG –ø–æ—à—É–∫
        try:
            rag_result = self.rag_engine.search(user_query)
            
            if rag_result['success']:
                answer = self.rag_engine.generate_answer(user_query, rag_result['context'])
                
                return {
                    'response': answer,
                    'source': 'RAG (–ë–∞–∑–∞ –∑–Ω–∞–Ω—å)',
                    'metadata': {
                        'score': rag_result['score'],
                        'sources': rag_result['sources'],
                        'mode': 'rag_only'
                    }
                }
            else:
                return {
                    'response': "‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –≤ –±–∞–∑—ñ –∑–Ω–∞–Ω—å. –°–ø—Ä–æ–±—É–π—Ç–µ —ñ–Ω—à–∏–π —Ä–µ–∂–∏–º –ø–æ—à—É–∫—É.",
                    'source': 'RAG (–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ)',
                    'metadata': {'mode': 'rag_only', 'no_results': True}
                }
        except Exception as e:
            return {
                'response': f"‚ùå –ü–æ–º–∏–ª–∫–∞ –±–∞–∑–∏ –∑–Ω–∞–Ω—å: {str(e)}",
                'source': 'RAG Error',
                'metadata': {'mode': 'rag_only', 'error': True}
            }
    
    def _process_hybrid(self, user_query: str) -> Dict[str, Any]:
        
        # 1. –°–ø—Ä–æ–±—É—î–º–æ function calling
        try:
            return {}
        except Exception as func_error:
            print(f"Function calling –ø–æ–º–∏–ª–∫–∞: {func_error}")
        try:
            rag_result = self.rag_engine.search(user_query)
            
            if rag_result['success'] and rag_result['score'] > 0.75:
                answer = self.rag_engine.generate_answer(user_query, rag_result['context'])
                
                return {
                    'response': answer,
                    'source': 'RAG (Pinecone)',
                    'metadata': {
                        'score': rag_result['score'],
                        'sources': rag_result['sources'],
                        'mode': 'hybrid'
                    }
                }
        except Exception as e:
            print(f"RAG –ø–æ—à—É–∫ –ø–æ–º–∏–ª–∫–∞: {e}")
        
        result = self._search_and_analyze_web(user_query)
        result['metadata']['mode'] = 'hybrid'
        return result
    
    def _research_mode(self, user_query: str) -> Dict[str, Any]:
        
        try:
            # –†–æ–∑—à–∏—Ä–µ–Ω–∏–π Google –ø–æ—à—É–∫
            search_result = self.google_search.search_with_analysis(user_query, num_results=5)
            
            if not search_result['success']:
                return {
                    'response': f"‚ùå –ü–æ–º–∏–ª–∫–∞ Google –ø–æ—à—É–∫—É: {search_result.get('error', '–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞')}",
                    'source': 'Google Search Error',
                    'metadata': {'error': True, 'mode': 'research'}
                }
            
            # –ó–±–∏—Ä–∞—î–º–æ –∫–æ–Ω—Ç–µ–Ω—Ç –∑ —É—Å—ñ—Ö –¥–∂–µ—Ä–µ–ª
            all_content = []
            valid_sources = []
            
            for source in search_result['sources']:
                if source['success'] and source['content'] and len(source['content']) > 50:
                    all_content.append(f"–î–∂–µ—Ä–µ–ª–æ: {source['title']}\n{source['content']}")
                    valid_sources.append(source)
            
            if not valid_sources:
                return {
                    'response': "‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –¥–ª—è –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è",
                    'source': 'Research Mode (No Data)',
                    'metadata': {'mode': 'research', 'no_data': True}
                }
            
            # –ü–æ–≥–ª–∏–±–ª–µ–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
            research_analysis = self._generate_research_analysis(
                user_query, 
                all_content, 
                valid_sources
            )
            
            return {
                'response': research_analysis,
                'source': 'Research Mode',
                'metadata': {
                    'sources_analyzed': len(valid_sources),
                    'total_sources': len(search_result['sources']),
                    'analysis_type': 'research',
                    'mode': 'research'
                }
            }
            
        except Exception as e:
            return {
                'response': f"‚ùå –ü–æ–º–∏–ª–∫–∞ –¥–æ—Å–ª—ñ–¥–Ω–∏—Ü—å–∫–æ–≥–æ —Ä–µ–∂–∏–º—É: {str(e)}",
                'source': 'Research Mode Error',
                'metadata': {'error': str(e), 'mode': 'research'}
            }

    def _generate_research_analysis(self, query: str, contents: List[str], sources: List[Dict]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–æ—Å–ª—ñ–¥–Ω–∏—Ü—å–∫–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É"""
        try:
            combined_content = "\n\n---\n\n".join(contents)
            
            # –û–±–º–µ–∂—É—î–º–æ —Ä–æ–∑–º—ñ—Ä
            max_tokens = 15000
            if len(combined_content) > max_tokens:
                combined_content = combined_content[:max_tokens] + "\n\n[–ö–æ–Ω—Ç–µ–Ω—Ç –æ–±—Ä—ñ–∑–∞–Ω–æ...]"
            
            system_prompt = """–¢–∏ - –µ–∫—Å–ø–µ—Ä—Ç–Ω–∏–π –¥–æ—Å–ª—ñ–¥–Ω–∏–∫ —Ç–∞ –∞–Ω–∞–ª—ñ—Ç–∏–∫. –¢–≤–æ—î –∑–∞–≤–¥–∞–Ω–Ω—è –ø—Ä–æ–≤–µ—Å—Ç–∏ –≥–ª–∏–±–æ–∫–∏–π –∞–Ω–∞–ª—ñ–∑ —Ç–µ–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫—ñ–ª—å–∫–æ—Ö –¥–∂–µ—Ä–µ–ª.

–°—Ç–≤–æ—Ä–∏ –¥–æ—Å–ª—ñ–¥–Ω–∏—Ü—å–∫–∏–π –∑–≤—ñ—Ç —â–æ –º—ñ—Å—Ç–∏—Ç—å:
1. üìã –†–µ–∑—é–º–µ —Ç–µ–º–∏
2. üîç –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∫–ª—é—á–æ–≤–∏—Ö –∞—Å–ø–µ–∫—Ç—ñ–≤
3. üìä –°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω—ñ –¥–∞–Ω—ñ —Ç–∞ —Ñ–∞–∫—Ç–∏ (—è–∫—â–æ —î)
4. üéØ –í–∏—Å–Ω–æ–≤–∫–∏ —Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
5. üîÆ –ü—Ä–æ–≥–Ω–æ–∑–∏ —Ç–∞ —Ç—Ä–µ–Ω–¥–∏ (—è–∫—â–æ –¥–æ—Ä–µ—á–Ω–æ)
6. ‚ùì –ü–∏—Ç–∞–Ω–Ω—è –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ–≥–æ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è

–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—É –ø–æ–¥–∞—á—É –∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏, —Å–ø–∏—Å–∫–∞–º–∏ —Ç–∞ –≤–∏–¥—ñ–ª–µ–Ω–Ω—è–º –≤–∞–∂–ª–∏–≤–∏—Ö –º–æ–º–µ–Ω—Ç—ñ–≤."""

            user_prompt = f"""–¢–µ–º–∞ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è: "{query}"

–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –Ω–∞—Å—Ç—É–ø–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é —Ç–∞ —Å—Ç–≤–æ—Ä–∏ –¥–µ—Ç–∞–ª—å–Ω–∏–π –¥–æ—Å–ª—ñ–¥–Ω–∏—Ü—å–∫–∏–π –∑–≤—ñ—Ç:

{combined_content}
"""

            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo-16k",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=2000,
                temperature=0.3
            )
            
            research_analysis = response.choices[0].message.content
            
            # –§–æ—Ä–º–∞—Ç—É—î–º–æ –∑–≤—ñ—Ç
            formatted_response = f"""# üî¨ –î–æ—Å–ª—ñ–¥–Ω–∏—Ü—å–∫–∏–π –∑–≤—ñ—Ç

{research_analysis}

---

## üìö –î–∂–µ—Ä–µ–ª–∞ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è:

"""
            
            for i, source in enumerate(sources, 1):
                formatted_response += f"""**{i}. {source['title']}**
üîó {source['url']}
üìä –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ —Å–ª—ñ–≤: {source['word_count']}
‚≠ê –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—å: {"üü¢ –í–∏—Å–æ–∫–∞" if source['word_count'] > 500 else "üü° –°–µ—Ä–µ–¥–Ω—è"}

"""
            
            formatted_response += f"\nüéØ *–î–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –±–∞–∑—É—î—Ç—å—Å—è –Ω–∞ {len(sources)} –¥–∂–µ—Ä–µ–ª–∞—Ö*"
            
            return formatted_response
            
        except Exception as e:
            return f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è: {str(e)}"

    def _search_and_analyze_web(self, user_query: str) -> Dict[str, Any]:
        
        try:
            # Google –ø–æ—à—É–∫
            search_result = self.google_search.search_with_analysis(user_query, num_results=3)
            
            if not search_result['success']:
                return {
                    'response': f"‚ùå –ü–æ–º–∏–ª–∫–∞ Google –ø–æ—à—É–∫—É: {search_result.get('error', '–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞')}",
                    'source': 'Google Search Error',
                    'metadata': {'error': True}
                }
            
            # –ó–±–∏—Ä–∞—î–º–æ –∫–æ–Ω—Ç–µ–Ω—Ç –∑ –¥–∂–µ—Ä–µ–ª
            valid_sources = []
            all_content = []
            
            for source in search_result['sources']:
                if source['success'] and source['content'] and len(source['content']) > 50:
                    all_content.append(source['content'][:2000])
                    valid_sources.append(source)
            
            if not valid_sources:
                return {
                    'response': "‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –∑ –≤–µ–±-–¥–∂–µ—Ä–µ–ª",
                    'source': 'Web Search (No Data)',
                    'metadata': {'no_data': True}
                }
            
            # –ì–µ–Ω–µ—Ä—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –æ—Å–Ω–æ–≤—ñ –≤–µ–±-–∫–æ–Ω—Ç–µ–Ω—Ç—É
            combined_content = "\n\n---\n\n".join(all_content)
            
            # –û–±–º–µ–∂—É—î–º–æ —Ä–æ–∑–º—ñ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç—É
            max_tokens = 6000
            if len(combined_content) > max_tokens:
                combined_content = combined_content[:max_tokens] + "\n\n[–ö–æ–Ω—Ç–µ–Ω—Ç –æ–±—Ä—ñ–∑–∞–Ω–æ...]"
            
            # –ì–µ–Ω–µ—Ä—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å —á–µ—Ä–µ–∑ OpenAI
            system_prompt = """–¢–∏ - –µ–∫—Å–ø–µ—Ä—Ç–Ω–∏–π –∞–Ω–∞–ª—ñ—Ç–∏–∫ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó. –ù–∞ –æ—Å–Ω–æ–≤—ñ –Ω–∞–¥–∞–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É –∑ –≤–µ–±-–¥–∂–µ—Ä–µ–ª –¥–∞–π –≤–∏—á–µ—Ä–ø–Ω—É —Ç–∞ —Ç–æ—á–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –∑–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞.

–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—É –ø–æ–¥–∞—á—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ —Ç–∞ —Å–ø–∏—Å–∫–∞–º–∏. –ü–æ—Å–∏–ª–∞–π—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ —Ñ–∞–∫—Ç–∏ –∑ –¥–∂–µ—Ä–µ–ª."""

            user_prompt = f"""–ó–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞: "{user_query}"

–ö–æ–Ω—Ç–µ–Ω—Ç –∑ –≤–µ–±-–¥–∂–µ—Ä–µ–ª:
{combined_content}

–î–∞–π –¥–µ—Ç–∞–ª—å–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ü—ñ—î—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó."""

            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo-16k",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=1500,
                temperature=0.3
            )
            
            web_analysis = response.choices[0].message.content
            
            # –§–æ—Ä–º–∞—Ç—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑ –¥–∂–µ—Ä–µ–ª–∞–º–∏
            formatted_response = f"""{web_analysis}

## üìö –î–∂–µ—Ä–µ–ª–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó:

"""
            
            for i, source in enumerate(valid_sources, 1):
                formatted_response += f"""**{i}. {source['title']}**
üîó {source['url']}
üìä –°–ª—ñ–≤: {source.get('word_count', 'N/A')}

"""
            
            return {
                'response': formatted_response,
                'source': 'Web Search Analysis',
                'metadata': {
                    'sources_count': len(valid_sources),
                    'total_searched': len(search_result['sources']),
                    'search_query': user_query
                }
            }
            
        except Exception as e:
            return {
                'response': f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤–µ–±-–ø–æ—à—É–∫—É: {str(e)}",
                'source': 'Web Search Error',
                'metadata': {'error': str(e)}
            }
    def process_user_message(self, user_input: str, user_id: str = "default") -> str:
        """–ì–æ–ª–æ–≤–Ω–∏–π –º–µ—Ç–æ–¥ –æ–±—Ä–æ–±–∫–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å"""
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–æ—á–∞—Ç–∫–æ–≤–∏–π —Å—Ç–∞–Ω
        initial_state = DialogueState(
            user_input=user_input,
            user_id=user_id
        )
        
        # –í–∏–∫–æ–Ω—É—î–º–æ workflow
        final_state = self.app.ainvoke(initial_state)
        
        return final_state.response_message