import os
import logging
from typing import List, Dict, Optional
from openai import OpenAI
from pinecone import Pinecone
from sentence_transformers import SentenceTransformer

class RAGEngine:
    """–°–∏—Å—Ç–µ–º–∞ –ø–æ—à—É–∫—É —á–µ—Ä–µ–∑ Pinecone RAG"""
    
    def __init__(self, pinecone_index_name: str):
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è Pinecone (–Ω–æ–≤–∏–π API)
        self.pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
    
        self.index_name = pinecone_index_name
        self.index = self.pc.Index(pinecone_index_name)
        self._detect_embedding_model()
        self._log_index_stats()
    
    def _detect_embedding_model(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ embedding"""
        try:
            stats = self.index.describe_index_stats()
            dimension = stats.dimension
            
            if dimension == 1536:
                self.embedding_model = "text-embedding-ada-002"
            elif dimension == 768:
                self.embedding_model = "local"  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ª–æ–∫–∞–ª—å–Ω—É –º–æ–¥–µ–ª—å
            elif dimension == 3072:
                self.embedding_model = "text-embedding-3-large"
            else:
                self.embedding_model = "local"  # fallback
                
        except Exception as e:
            self.embedding_model = "local"
    
    def _log_index_stats(self):
        try:
            stats = self.index.describe_index_stats()
            if stats.namespaces:
                for ns, data in stats.namespaces.items():
                    ns_name = ns if ns else "''"
                    logging.info(f"   Namespace {ns_name}: {data['vector_count']} –≤–µ–∫—Ç–æ—Ä—ñ–≤")
        except Exception as e:
            logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
    
    def search(self, query: str, top_k: int = 5) -> Dict:
        try:
            stats = self.index.describe_index_stats()
            total_vectors = stats.total_vector_count                   
            if total_vectors == 0:
                return {
                    'success': False,
                    'context': '',
                    'score': 0.0,
                    'sources': [],
                    'raw_results': [],
                    'message': '–ë–∞–∑–∞ –∑–Ω–∞–Ω—å –ø–æ—Ä–æ–∂–Ω—è'
                }
            
            # –ì–µ–Ω–µ—Ä—É—î–º–æ embedding –¥–ª—è –∑–∞–ø–∏—Ç—É
            embedding = self._get_embedding(query)
            
            # –®—É–∫–∞—î–º–æ –≤ default namespace (–¥–µ –±—ñ–ª—å—à–µ –≤–µ–∫—Ç–æ—Ä—ñ–≤)
            results = self.index.query(
                vector=embedding,
                top_k=top_k,
                include_metadata=True,
                namespace="default"  # ‚Üê –ö–ª—é—á–æ–≤–µ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è!
            )
                    
            # –Ø–∫—â–æ –≤ default –º–∞–ª–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤, —Å–ø—Ä–æ–±—É—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ–π namespace
            if len(results.matches) < top_k // 2:
                empty_results = self.index.query(
                    vector=embedding,
                    top_k=top_k,
                    include_metadata=True,
                    namespace=""  # –ü–æ—Ä–æ–∂–Ω—ñ–π namespace
                )                
                # –û–±'—î–¥–Ω—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
                all_matches = list(results.matches) + list(empty_results.matches)
                # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ score
                all_matches.sort(key=lambda x: x.score, reverse=True)
                results.matches = all_matches[:top_k]
            
            if not results.matches:
                return {
                    'success': False,
                    'context': '',
                    'score': 0.0,
                    'sources': [],
                    'raw_results': [],
                    'message': '–í –±–∞–∑—ñ –∑–Ω–∞–Ω—å –Ω—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ'
                }
            
            # –ó–±–∏—Ä–∞—î–º–æ –≤—Å—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            all_results = []
            context_parts = []
            sources = []
            total_score = 0
            
            for i, match in enumerate(results.matches, 1):
                result_info = {
                    'rank': i,
                    'score': round(match.score, 3),
                    'id': match.id,
                    'text': match.metadata.get('text', ''),
                    'source': match.metadata.get('source', 'Unknown'),
                    'title': match.metadata.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∏'),
                    'is_relevant': match.score > 0.7
                }
                all_results.append(result_info)
                
                # –î–æ–¥–∞—î–º–æ –¥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É —Ç—ñ–ª—å–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ
                if match.score > 0.7:
                    context_parts.append(match.metadata.get('text', ''))
                    sources.append({
                        'id': match.id,
                        'score': match.score,
                        'source': match.metadata.get('source', 'Unknown'),
                        'title': match.metadata.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∏')
                    })
                    total_score += match.score
            
            avg_score = total_score / len(sources) if sources else 0
            
            return {
                'success': len(context_parts) > 0,
                'context': '\n\n'.join(context_parts),
                'score': avg_score,
                'sources': sources,
                'raw_results': all_results,
                'total_found': len(results.matches),
                'relevant_count': len(context_parts),
                'message': f'–ó–Ω–∞–π–¥–µ–Ω–æ {len(results.matches)} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤, {len(context_parts)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö'
            }
            
        except Exception as e:
            return {
                'success': False,
                'context': '',
                'score': 0.0,
                'sources': [],
                'raw_results': [],
                'error': str(e),
                'message': f'–ü–æ–º–∏–ª–∫–∞ –ø–æ—à—É–∫—É: {str(e)}'
            }
    
    def _get_embedding(self, text: str) -> List[float]:
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è embedding (—Ç–æ–π –∂–µ –º–µ—Ç–æ–¥ —â–æ —ñ –≤ DocumentLoader)"""
        try:
            if self.embedding_model == "local":
                return self._get_local_embedding(text)
            else:
                response = self.openai_client.embeddings.create(
                    input=text,
                    model=self.embedding_model
                )
                return response.data[0].embedding
        except Exception as e:
            return self._get_local_embedding(text)
    
    def _get_local_embedding(self, text: str) -> List[float]:
        """–õ–æ–∫–∞–ª—å–Ω–∏–π embedding (—Ç–æ—á–Ω–æ —Ç–æ–π –∂–µ —â–æ DocumentLoader)"""
        try:            
            # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ –º–æ–¥–µ–ª—å —è–∫—â–æ —â–µ –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞
            if not hasattr(self, '_local_model'):
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –¢–£ –ñ –°–ê–ú–£ –º–æ–¥–µ–ª—å —â–æ —ñ DocumentLoader
                self._local_model = SentenceTransformer('intfloat/multilingual-e5-base')
            
            embedding = self._local_model.encode(text).tolist()
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å
            stats = self.index.describe_index_stats()
            expected_dim = stats.dimension
            
            if len(embedding) != expected_dim:                
                if len(embedding) > expected_dim:
                    embedding = embedding[:expected_dim]
                elif len(embedding) < expected_dim:
                    # –†–æ–∑—à–∏—Ä—é—î–º–æ –≤–µ–∫—Ç–æ—Ä
                    while len(embedding) < expected_dim:
                        remaining = expected_dim - len(embedding)
                        if remaining >= len(embedding):
                            embedding.extend(embedding)
                        else:
                            embedding.extend(embedding[:remaining])
                    embedding = embedding[:expected_dim]
            
            return embedding
            
        except ImportError:
            raise Exception("–í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å: pip install sentence-transformers")
        except Exception as e:
            raise e
    
    def generate_answer(self, query: str, context: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É"""
        try:
            system_prompt = f"""
–¢–∏ –∫–æ—Ä–∏—Å–Ω–∏–π –∞—Å–∏—Å—Ç–µ–Ω—Ç. –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é –Ω–∞ –æ—Å–Ω–æ–≤—ñ –Ω–∞–¥–∞–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É.

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–Ø–∫—â–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –Ω–µ–º–∞—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –¥–ª—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –∑–∞–ø–∏—Ç, —Å–∫–∞–∂–∏ —â–æ –Ω–µ –∑–Ω–∞—î—à.
–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π –¥–µ—Ç–∞–ª—å–Ω–æ —Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–æ.
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": query}
                ],
                temperature=0.3,
                max_tokens=800
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return "–í–∏–±–∞—á—Ç–µ, —Å—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ."
    
    def format_search_results(self, rag_result: Dict) -> str:
        """–§–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø–æ—à—É–∫—É –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è"""
        if not rag_result.get('raw_results'):
            return "üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø–æ—à—É–∫—É –Ω–µ–º–∞—î"
        
        output = []
        output.append(f"üîç **–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—à—É–∫—É –≤ –±–∞–∑—ñ –∑–Ω–∞–Ω—å:**")
        output.append(f"üìä {rag_result.get('message', '')}")
        output.append("")
        
        for result in rag_result['raw_results']:
            relevance_icon = "‚úÖ" if result['is_relevant'] else "‚ö†Ô∏è"
            score_percent = f"{result['score']*100:.1f}%"
            
            output.append(f"{relevance_icon} **#{result['rank']} - {result['title']}** ({score_percent})")
            
            # –ü–æ–∫–∞–∑—É—î–º–æ –ø–µ—Ä—à—ñ 150 —Å–∏–º–≤–æ–ª—ñ–≤ —Ç–µ–∫—Å—Ç—É
            text_preview = result['text'][:150] + "..." if len(result['text']) > 150 else result['text']
            output.append(f"üìÑ {text_preview}")
            output.append(f"üè∑Ô∏è –î–∂–µ—Ä–µ–ª–æ: {result['source']}")
            output.append("")
        
        return "\n".join(output)