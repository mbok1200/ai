import torch
import streamlit as st
import json
import random
import re
from peft import PeftModel
from transformers import AutoTokenizer, AutoModelForCausalLM

# --- –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è ---
base_model_name = "google/gemma-2-2b"
lora_path = "/home/mikola/projects/ai/hr-assistant-finetune-1/lora_hr_assistant_v2"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

@st.cache_resource
def load_model():
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∑ –∫–µ—à—É–≤–∞–Ω–Ω—è–º"""
    try:
        tokenizer = AutoTokenizer.from_pretrained(base_model_name, use_fast=True)
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token

        base_model = AutoModelForCausalLM.from_pretrained(
            base_model_name,
            torch_dtype=torch.float16,
            attn_implementation='eager'
        )
        
        model = PeftModel.from_pretrained(base_model, lora_path)
        model = model.merge_and_unload()
        model.to(device)
        model.eval()
        
        return tokenizer, model
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ: {e}")
        return None, None

def build_prompt(input_text: str) -> str:
    """–°—Ç–≤–æ—Ä—é—î –ø—Ä–æ–º–ø—Ç —Ç–æ—á–Ω–æ —è–∫ —É –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö"""
    system_prompt = """–¢–∏ HR-–∞—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ —Å–∏—Å—Ç–µ–º–æ—é Redmine. –¢–≤–æ—è –º–µ—Ç–∞:
‚Ä¢ –†–æ–∑—É–º—ñ—Ç–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ –∑–∞–ø–∏—Ç–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
‚Ä¢ –ì–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –ø—Ä–∏—Ä–æ–¥–Ω—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é
‚Ä¢ –í–∏–∑–Ω–∞—á–∞—Ç–∏ –ø–æ—Ç—Ä—ñ–±–Ω—É —Ñ—É–Ω–∫—Ü—ñ—é —Ç–∞ —ó—ó –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
‚Ä¢ –ù–∞–¥–∞–≤–∞—Ç–∏ –∫–æ—Ä–∏—Å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é

–ë—É–¥—å –≤–≤—ñ—á–ª–∏–≤–∏–º, –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–º —Ç–∞ –∫–æ—Ä–∏—Å–Ω–∏–º."""

    return f"""{system_prompt}

–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á: {input_text}

–ê—Å–∏—Å—Ç–µ–Ω—Ç:"""

def generate_response(tokenizer, model, prompt: str, max_new_tokens: int = 300, temperature: float = 0.7):
    """–ì–µ–Ω–µ—Ä—É—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å –º–æ–¥–µ–ª—ñ"""
    try:
        inputs = tokenizer(prompt, return_tensors="pt").to(device)
        
        with torch.no_grad():
            output_ids = model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                do_sample=True,
                temperature=temperature,
                top_p=0.9,
                repetition_penalty=1.1,
                pad_token_id=tokenizer.eos_token_id,
                eos_token_id=tokenizer.eos_token_id,
                early_stopping=True,
                no_repeat_ngram_size=2
            )
        
        generated_tokens = output_ids[0][inputs['input_ids'].shape[1]:]
        response = tokenizer.decode(generated_tokens, skip_special_tokens=True)
        
        return response.strip()
    except Exception as e:
        return f"–ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó: {e}"

def extract_function_info(response_text: str):
    """–í–∏—Ç—è–≥—É—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ñ—É–Ω–∫—Ü—ñ—ó –∑ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ"""
    # –®—É–∫–∞—î–º–æ JSON –±–ª–æ–∫–∏
    json_patterns = [
        r'\{[^{}]*"function_call"[^{}]*\}',
        r'\{[^{}]*"name"[^{}]*"arguments"[^{}]*\}'
    ]
    
    function_calls = []
    for pattern in json_patterns:
        matches = re.findall(pattern, response_text, re.DOTALL)
        for match in matches:
            try:
                func_data = json.loads(match)
                if 'function_call' in func_data:
                    function_calls.append(func_data['function_call'])
                elif 'name' in func_data and 'arguments' in func_data:
                    function_calls.append(func_data)
            except json.JSONDecodeError:
                continue
    
    return function_calls

def get_real_examples_from_dataset():
    """–ü–æ–≤–µ—Ä—Ç–∞—î —Ä–µ–∞–ª—å–Ω—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ –∑ –¥–∞—Ç–∞—Å–µ—Ç—É"""
    return [
        # –ó–∞–≤–¥–∞–Ω–Ω—è –∑–∞ –¥–∞—Ç–æ—é (—Ç–æ—á–Ω–æ –∑ –¥–∞—Ç–∞—Å–µ—Ç—É)
        "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è",
        "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ —Å—å–æ–≥–æ–¥–Ω—ñ", 
        "—à–æ —Ç–∞–º –≤ –º–µ–Ω–µ –ø–æ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ –∑–∞–≤—Ç—Ä–∞",
        "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ —Ç–∏–∂–¥–µ–Ω—å",
        "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ –º—ñ—Å—è—Ü—å",
        "—â–æ –ø–æ –∑–∞–≤–¥–∞–Ω–Ω—è–º –Ω–∞ —Ä—ñ–∫",
        "—â–æ –≤ –º–µ–Ω–µ –∑–∞ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ 23.04",
        "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ 23.04.2025",
        "—à–æ —Ç–∞–º –ø–æ –∑–∞–¥–∞—á–∞–º –Ω–∞ 23.04.2025 12:00",
        
        # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è (–∑ –¥–∞—Ç–∞—Å–µ—Ç—É)
        "—â–æ –∑–∞ –∑–∞–≤–¥–∞–Ω–Ω—è #33456",
        "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è #33456",
        "#33456 —à–æ —Ç–∞–º –ø–æ –∑–∞–≤–¥–∞–Ω–Ω—é",
        "Bug 453465",
        "—â–æ –∑–∞ —Ç–∞—Å–∫–∞ Bug 453465",
        "#Bug 453465 —à–æ —Ç–∞–º –ø–æ –∑–∞–≤–¥–∞–Ω–Ω—é",
        "–∑–∞–≤–¥–∞–Ω–Ω—è User Story #4534690",
        "User Story 453780",
        "—â–æ –∑–∞ User Story 453799",
        
        # –°—Ç–∞—Ç—É—Å (–∑ –¥–∞—Ç–∞—Å–µ—Ç—É)
        "—Å—Ç–∞—Ç—É—Å –∑–∞–≤–¥–∞–Ω–Ω—è 453799",
        "User Story 453759 —Å—Ç–∞—Ç—É—Å –∑–∞–≤–¥–∞–Ω–Ω—è",
        "#453799 —è–∫–∏–π —Å—Ç–∞—Ç—É—Å",
        "—Å—Ç–∞—Ç—É—Å –∑–∞–≤–¥–∞–Ω–Ω—è #453799",
        "—Å—Ç–∞—Ç—É—Å User Story 453759",
        
        # –ì–æ–¥–∏–Ω–∏ (–∑ –¥–∞—Ç–∞—Å–µ—Ç—É)
        "–°–∫—ñ–ª—å–∫–∏ –≥–æ–¥–∏–Ω –≤–∏—Ç—Ä–∞—á–µ–Ω–æ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è 453799",
        "#453799 —Å–∫—ñ–ª—å–∫–∏ –≥–æ–¥–∏–Ω –≤–∏—Ç—Ä–∞—á–µ–Ω–æ",
        "#453799 —Å–∫—ñ–ª—å–∫–∏ –≥–æ–¥–∏–Ω –≤–∏—Ç—Ä–∞—á–µ–Ω–æ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è",
        "User Story 453759 —Å–∫—ñ–ª—å–∫–∏ –≥–æ–¥–∏–Ω –≤–∏—Ç—Ä–∞—á–µ–Ω–æ",
        
        # –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –≥–æ–¥–∏–Ω (–∑ –¥–∞—Ç–∞—Å–µ—Ç—É)
        "–∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –≥–æ–¥–∏–Ω–∏",
        "–∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –≥–æ–¥–∏–Ω–∏ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è #453799 2 –≥–æ–¥–∏–Ω–∏",
        "–∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –≥–æ–¥–∏–Ω–∏ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è User Story 453759 3 –≥–æ–¥–∏–Ω–∏",
        "–∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –≥–æ–¥–∏–Ω–∏ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è #453799 4 –≥–æ–¥–∏–Ω–∏ –Ω–∞ –≤—á–æ—Ä–∞",
        "–∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –≥–æ–¥–∏–Ω–∏ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è User Story 453759 5 –≥–æ–¥–∏–Ω –Ω–∞ 23.04",
        "–∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –≥–æ–¥–∏–Ω–∏ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è #453799 6 –≥–æ–¥–∏–Ω –Ω–∞ 22.04.2025",
        "User Story 453759 8 –≥–æ–¥–∏–Ω –Ω–∞ 29.04.2025 12:00 –∑—Ä–æ–±–∏–≤ —Ç–µ—Å—Ç",
        "#453799 8 –≥–æ–¥–∏–Ω –Ω–∞ 30.04.2025 12:00 –∑—Ä–æ–±–∏–≤ —Ä–µ–≤'—é",
        
        # –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á (–∑ –¥–∞—Ç–∞—Å–µ—Ç—É)
        "–º—ñ–π —Å—Ç–∞—Ç—É—Å",
        "—Å—Ç–∞—Ç—É—Å –º–æ–≥–æ –∞–∫–∞—É–Ω—Ç—É", 
        "—è –∑–∞—Ä–∞–∑ –Ω–∞ —Ä–æ–±–æ—Ç—ñ?",
        "—è –Ω–∞ –ª—ñ–∫–∞—Ä–Ω—è–Ω–æ–º—É",
        "—è –Ω–∞ —Ä–æ–±–æ—Ç—ñ",
        "—è –≤–¥–æ–º–∞",
        
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è (–∑ –¥–∞—Ç–∞—Å–µ—Ç—É)
        "—Å—Ç–≤–æ—Ä–∏ –∑–∞–≤–¥–∞–Ω–Ω—è",
        "—Å—Ç–≤–æ—Ä–∏ –∑–∞–≤–¥–∞–Ω–Ω—è –∑ –Ω–∞–∑–≤–æ—é '–ù–æ–≤–∏–π –ø—Ä–æ–µ–∫—Ç' —ñ –æ–ø–∏—Å–æ–º '–û–ø–∏—Å –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç—É'",
        "User Story 453759: bug with login",
        "#453799: fix issue with payment",
        "–∑–∞–≤–¥–∞–Ω–Ω—è #453459: add new feature, -add new button for exist menu",
        
        # –ü—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è (–∑ –¥–∞—Ç–∞—Å–µ—Ç—É)
        "#459859 –Ω–∞–∑–Ω–∞—á–∏—Ç–∏",
        "#498459 –Ω–∞–∑–Ω–∞—á–∏—Ç–∏ Yuri",
        "User Story 434256",
        "User Story 434256 –Ω–∞–∑–Ω–∞—á–∏—Ç–∏ Yuri",
        "–Ω–∞–∑–Ω–∞—á–∏—Ç–∏ –Ω–∞ Yuri User Story 434256",
        
        # Wiki (–∑ –¥–∞—Ç–∞—Å–µ—Ç—É)
        "wiki —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è",
        "wiki —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ø—Ä–æ–µ–∫—Ç",
        "wiki —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –∫–æ–Ω—Ç–∞–∫—Ç–∏ –¥–ª—è –ª–µ–Ω–¥–∏–≥—ñ–≤ —Ç–∞ —Å–∞–π—Ç—ñ–≤ –∫–æ–º–ø–∞–Ω—ñ—ó"
    ]

def create_expected_responses():
    """–°—Ç–≤–æ—Ä—é—î –æ—á—ñ–∫—É–≤–∞–Ω—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –¥–∞—Ç–∞—Å–µ—Ç—É"""
    return {
        "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ —Å—å–æ–≥–æ–¥–Ω—ñ": {
            "expected_function": "get_issue_by_date",
            "expected_args": {"value_1": "today"},
            "mock_result": "üìÖ –ó–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ —Å—å–æ–≥–æ–¥–Ω—ñ: #453231, #453232, #453233"
        },
        "—â–æ –≤ –º–µ–Ω–µ –∑–∞ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ 23.04": {
            "expected_function": "get_issue_by_date", 
            "expected_args": {"value_1": "23.04.2025"},
            "mock_result": "üìÖ –ó–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ 23.04: #453245, #453246"
        },
        "—â–æ –∑–∞ –∑–∞–≤–¥–∞–Ω–Ω—è #33456": {
            "expected_function": "get_issue_by_id",
            "expected_args": {"value_1": "33456"},
            "mock_result": "üìã –ó–∞–≤–¥–∞–Ω–Ω—è #33456: '–†–æ–∑—Ä–æ–±–∫–∞ API' (–°—Ç–∞—Ç—É—Å: –í —Ä–æ–±–æ—Ç—ñ)"
        },
        "Bug 453465": {
            "expected_function": "get_issue_by_name",
            "expected_args": {"value_1": "Bug 453465"},
            "mock_result": "üêõ Bug 453465: '–ü–æ–º–∏–ª–∫–∞ –ª–æ–≥—ñ–Ω—É' (–ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç: –í–∏—Å–æ–∫–∏–π)"
        },
        "—Å—Ç–∞—Ç—É—Å –∑–∞–≤–¥–∞–Ω–Ω—è 453799": {
            "expected_function": "get_issue_status",
            "expected_args": {"value_1": "453799"},
            "mock_result": "üìä –°—Ç–∞—Ç—É—Å –∑–∞–≤–¥–∞–Ω–Ω—è 453799: –í —Ä–æ–±–æ—Ç—ñ ‚Üí –ù–∞ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—ñ"
        },
        "–∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –≥–æ–¥–∏–Ω–∏ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è #453799 2 –≥–æ–¥–∏–Ω–∏": {
            "expected_function": "fill_issue_hours",
            "expected_args": {"value_1": "#453799", "value_2": "2", "value_3": "today"},
            "mock_result": "‚úÖ –ó–∞–ø–æ–≤–Ω–µ–Ω–æ 2 –≥–æ–¥–∏–Ω–∏ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è #453799 –∑–∞ —Å—å–æ–≥–æ–¥–Ω—ñ"
        },
        "—è –Ω–∞ —Ä–æ–±–æ—Ç—ñ": {
            "expected_function": "set_user_status",
            "expected_args": {"value_1": "on_work"},
            "mock_result": "üë§ –°—Ç–∞—Ç—É—Å –∑–º—ñ–Ω–µ–Ω–æ –Ω–∞: –ù–∞ —Ä–æ–±–æ—Ç—ñ"
        },
        "—Å—Ç–≤–æ—Ä–∏ –∑–∞–≤–¥–∞–Ω–Ω—è": {
            "expected_function": "create_issue",
            "expected_args": {"value_1": "", "value_2": "", "value_3": "assign_me"},
            "mock_result": "‚ûï –ü–æ—Ç—Ä—ñ–±–Ω—ñ –¥–µ—Ç–∞–ª—ñ –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑–∞–≤–¥–∞–Ω–Ω—è"
        }
    }

# --- Streamlit UI ---
st.set_page_config(
    page_title="HR Assistant - –¢–æ—á–Ω–∞ —Ä–µ–ø–ª—ñ–∫–∞—Ü—ñ—è –¥–∞—Ç–∞—Å–µ—Ç—É",
    page_icon="ü§ñ",
    layout="wide"
)

st.title("ü§ñ HR Assistant - –ù–∞–≤—á–µ–Ω–∏–π –Ω–∞ —Ä–µ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö")
st.markdown("*–ú–æ–¥–µ–ª—å –Ω–∞–≤—á–µ–Ω–∞ –Ω–∞ 58 —Ç–æ—á–Ω–∏—Ö –ø—Ä–∏–∫–ª–∞–¥–∞—Ö –∑ merged_with_links_is.jsonl*")

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
with st.spinner("‚è≥ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ..."):
    tokenizer, model = load_model()

if tokenizer is None or model is None:
    st.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å")
    st.stop()

st.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ (Loss: 1.64 ‚Üí 0.039)")

# –ë—ñ—á–Ω–∞ –ø–∞–Ω–µ–ª—å –∑ —Ä–µ–∞–ª—å–Ω–∏–º–∏ –ø—Ä–∏–∫–ª–∞–¥–∞–º–∏
st.sidebar.header("üìã –ü—Ä–∏–∫–ª–∞–¥–∏ –∑ –¥–∞—Ç–∞—Å–µ—Ç—É")
st.sidebar.markdown("*–¢–æ—á–Ω—ñ –∑–∞–ø–∏—Ç–∏ –∑ –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö*")

real_examples = get_real_examples_from_dataset()
expected_responses = create_expected_responses()

selected_example = st.sidebar.selectbox(
    "–û–±–µ—Ä—ñ—Ç—å –ø—Ä–∏–∫–ª–∞–¥ (–∑ merged_with_links_is.jsonl):",
    [""] + real_examples
)

# –ü–æ–∫–∞–∑—É—î–º–æ –æ—á—ñ–∫—É–≤–∞–Ω—É —Ñ—É–Ω–∫—Ü—ñ—é –¥–ª—è –≤–∏–±—Ä–∞–Ω–æ–≥–æ –ø—Ä–∏–∫–ª–∞–¥—É
if selected_example and selected_example in expected_responses:
    expected = expected_responses[selected_example]
    st.sidebar.markdown("### üéØ –û—á—ñ–∫—É–≤–∞–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è:")
    st.sidebar.code(f"""
–§—É–Ω–∫—Ü—ñ—è: {expected['expected_function']}
–ê—Ä–≥—É–º–µ–Ω—Ç–∏: {expected['expected_args']}
    """)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑ –¥–∞—Ç–∞—Å–µ—Ç—É
st.sidebar.markdown("---")
st.sidebar.markdown("### üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç—É")
st.sidebar.metric("–í—Å—å–æ–≥–æ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤", "58", "100% –ø–æ–∫—Ä–∏—Ç—Ç—è")
st.sidebar.metric("–ù–∞–≤—á–∞–ª—å–Ω–∏—Ö", "52", "90%")
st.sidebar.metric("–¢–µ—Å—Ç–æ–≤–∏—Ö", "6", "10%")
st.sidebar.metric("–§—É–Ω–∫—Ü—ñ–π", "11", "Redmine API")

# –ü–æ–∫–∞–∑—É—î–º–æ —Ä–æ–∑–ø–æ–¥—ñ–ª —Ñ—É–Ω–∫—Ü—ñ–π —É –¥–∞—Ç–∞—Å–µ—Ç—ñ
function_counts = {
    "get_issue_by_date": 9,
    "get_issue_by_id": 3, 
    "get_issue_by_name": 6,
    "get_issue_status": 5,
    "get_issue_hours": 4,
    "fill_issue_hours": 11,
    "get_user_status": 4,
    "set_user_status": 2,
    "create_issue": 8,
    "assign_issue": 6,
    "get_wiki_info": 3
}

st.sidebar.markdown("### üìà –†–æ–∑–ø–æ–¥—ñ–ª —É –¥–∞—Ç–∞—Å–µ—Ç—ñ:")
for func, count in function_counts.items():
    percentage = (count / 58) * 100
    st.sidebar.write(f"**{func}**: {count} ({percentage:.1f}%)")

# –û—Å–Ω–æ–≤–Ω–∏–π —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("üì• –í–≤–µ–¥—ñ—Ç—å –∑–∞–ø–∏—Ç")
    
    input_text = st.text_area(
        "–ó–∞–ø–∏—Ç —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é:",
        value=selected_example,
        placeholder="–ù–∞–ø—Ä–∏–∫–ª–∞–¥: —è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ —Å—å–æ–≥–æ–¥–Ω—ñ",
        height=150
    )
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
    col1_1, col1_2 = st.columns(2)
    with col1_1:
        max_tokens = st.slider("–ú–∞–∫—Å. —Ç–æ–∫–µ–Ω—ñ–≤:", 50, 512, 300)
    with col1_2:
        temperature = st.slider("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:", 0.1, 1.0, 0.7, 0.1)
    
    generate_button = st.button("üöÄ –ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å", type="primary", use_container_width=True)

with col2:
    st.subheader("üì§ –í—ñ–¥–ø–æ–≤—ñ–¥—å HR Assistant")
    
    if generate_button:
        if not input_text.strip():
            st.warning("‚ö†Ô∏è –í–≤–µ–¥—ñ—Ç—å —Ç–µ–∫—Å—Ç –∑–∞–ø–∏—Ç—É")
        else:
            with st.spinner("ü§ñ –ú–æ–¥–µ–ª—å –∞–Ω–∞–ª—ñ–∑—É—î –∑–∞–ø–∏—Ç..."):
                prompt = build_prompt(input_text)
                response = generate_response(tokenizer, model, prompt, max_tokens, temperature)
                
                # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
                st.text_area(
                    "–ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å:",
                    value=response,
                    height=150,
                    disabled=True
                )
                
                # –ê–Ω–∞–ª—ñ–∑ —Ñ—É–Ω–∫—Ü—ñ–π
                function_calls = extract_function_info(response)
                
                if function_calls:
                    st.subheader("‚öôÔ∏è –í–∏—è–≤–ª–µ–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó")
                    for i, func_call in enumerate(function_calls, 1):
                        with st.expander(f"üîß Function #{i}: `{func_call.get('name', 'unknown')}`", expanded=True):
                            st.json(func_call)
                            
                            # –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ –æ—á—ñ–∫—É–≤–∞–Ω–∏–º
                            if input_text in expected_responses:
                                expected = expected_responses[input_text]
                                func_name = func_call.get('name', '')
                                
                                if func_name == expected['expected_function']:
                                    st.success(f"‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è: {func_name}")
                                else:
                                    st.error(f"‚ùå –û—á—ñ–∫—É–≤–∞–ª–æ—Å—å: {expected['expected_function']}, –æ—Ç—Ä–∏–º–∞–Ω–æ: {func_name}")
                                
                                # –ú–æ–∫–æ–≤–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
                                st.info(f"üì° –ú–æ–∫–æ–≤–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å: {expected['mock_result']}")
                            else:
                                # –ó–∞–≥–∞–ª—å–Ω–∞ –º–æ–∫–æ–≤–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
                                mock_responses = {
                                    'get_issue_by_date': f"üìÖ –ó–Ω–∞–π–¥–µ–Ω–æ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ –¥–∞—Ç—É",
                                    'get_issue_by_id': f"üìã –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –∑–∞–≤–¥–∞–Ω–Ω—è",
                                    'get_issue_by_name': f"üîç –ó–Ω–∞–π–¥–µ–Ω–æ –∑–∞–≤–¥–∞–Ω–Ω—è",
                                    'get_issue_status': f"üìä –°—Ç–∞—Ç—É—Å –∑–∞–≤–¥–∞–Ω–Ω—è",
                                    'get_issue_hours': f"‚è±Ô∏è –ì–æ–¥–∏–Ω–∏ –ø–æ –∑–∞–≤–¥–∞–Ω–Ω—é",
                                    'fill_issue_hours': f"‚úÖ –ì–æ–¥–∏–Ω–∏ –∑–∞–ø–æ–≤–Ω–µ–Ω—ñ",
                                    'get_user_status': "üë§ –°—Ç–∞—Ç—É—Å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞",
                                    'set_user_status': f"üîÑ –°—Ç–∞—Ç—É—Å –æ–Ω–æ–≤–ª–µ–Ω–æ",
                                    'create_issue': f"‚ûï –ó–∞–≤–¥–∞–Ω–Ω—è —Å—Ç–≤–æ—Ä–µ–Ω–æ",
                                    'assign_issue': f"üë• –ó–∞–≤–¥–∞–Ω–Ω—è –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–æ",
                                    'get_wiki_info': f"üìö Wiki —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è"
                                }
                                
                                func_name = func_call.get('name', '')
                                mock_response = mock_responses.get(func_name, f"‚öôÔ∏è –§—É–Ω–∫—Ü—ñ—è {func_name} –≤–∏–∫–æ–Ω–∞–Ω–∞")
                                st.info(f"üì° –ú–æ–∫–æ–≤–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å: {mock_response}")
                else:
                    st.warning("üîç –§—É–Ω–∫—Ü—ñ—ó –Ω–µ –≤–∏—è–≤–ª–µ–Ω–æ –≤ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ")
                    if any(keyword in response.lower() for keyword in ['–∑–∞–≤–¥–∞–Ω–Ω—è', '—Å—Ç–∞—Ç—É—Å', '–≥–æ–¥–∏–Ω–∏', '—Å—Ç–≤–æ—Ä–∏']):
                        st.info("üí° –ú–æ–¥–µ–ª—å —Ä–æ–∑–ø—ñ–∑–Ω–∞–ª–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç, –∞–ª–µ –Ω–µ –∑–≥–µ–Ω–µ—Ä—É–≤–∞–ª–∞ JSON")

# –†–æ–∑–¥—ñ–ª –∑ –ø—Ä–æ–≥—Ä–µ—Å–æ–º –Ω–∞–≤—á–∞–Ω–Ω—è
st.markdown("---")
st.subheader("üìà –ü—Ä–æ–≥—Ä–µ—Å –Ω–∞–≤—á–∞–Ω–Ω—è")

# –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("–ü–æ—á–∞—Ç–∫–æ–≤–∏–π Loss", "1.6428", "–ï–ø–æ—Ö–∞ 0.77")
with col2:
    st.metric("–§—ñ–Ω–∞–ª—å–Ω–∏–π Loss", "0.039", "-97.6% ‚úÖ")
with col3:
    st.metric("Eval Loss", "0.231", "–°—Ç–∞–±—ñ–ª—å–Ω–∏–π")
with col4:
    st.metric("–ì—Ä–∞–¥—ñ—î–Ω—Ç", "0.45", "–ö–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü—ñ—è ‚úÖ")

# –†–æ–∑–¥—ñ–ª –∑ –∞–Ω–∞–ª—ñ–∑–æ–º –¥–∞—Ç–∞—Å–µ—Ç—É
st.markdown("---")
st.subheader("üìä –ê–Ω–∞–ª—ñ–∑ –Ω–∞–≤—á–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç—É")

# –ü–æ–∫–∞–∑—É—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ñ—É–Ω–∫—Ü—ñ—è—Ö
import pandas as pd

df_functions = pd.DataFrame([
    {"–§—É–Ω–∫—Ü—ñ—è": func, "–ö—ñ–ª—å–∫—ñ—Å—Ç—å": count, "–í—ñ–¥—Å–æ—Ç–æ–∫": f"{(count/58)*100:.1f}%"} 
    for func, count in function_counts.items()
]).sort_values("–ö—ñ–ª—å–∫—ñ—Å—Ç—å", ascending=False)

st.dataframe(df_functions, use_container_width=True)

# –ü—Ä–∏–∫–ª–∞–¥–∏ —Ñ–æ—Ä–º–∞—Ç—ñ–≤ –∑ –¥–∞—Ç–∞—Å–µ—Ç—É
st.markdown("---")
st.subheader("üéØ –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏ (–∑ –¥–∞—Ç–∞—Å–µ—Ç—É)")

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("**üìÖ –î–∞—Ç–∏:**")
    st.code("""
today
tomorrow  
week
month
year
23.04
23.04.2025
23.04.2025 12:00
    """)

with col2:
    st.markdown("**üî¢ –ù–æ–º–µ—Ä–∏ –∑–∞–≤–¥–∞–Ω—å:**")
    st.code("""
#33456
453799
#453799
Bug 453465
#Bug 453465
User Story 453759
User Story #453759
    """)

with col3:
    st.markdown("**üë§ –°—Ç–∞—Ç—É—Å–∏:**")
    st.code("""
on_work
off_work
assign_me
Yuri
ossystem
    """)

# –§—É—Ç–µ—Ä
st.markdown("---")
st.info("""
üéØ **–û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ —Ü—ñ—î—ó –º–æ–¥–µ–ª—ñ:** –ù–∞–≤—á–µ–Ω–∞ –Ω–∞ —Ç–æ—á–Ω–∏—Ö 58 –ø—Ä–∏–∫–ª–∞–¥–∞—Ö –∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ä–æ–±–æ—á–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—É Redmine. 
–ú–æ–¥–µ–ª—å —Ä–æ–∑—É–º—ñ—î —É–∫—Ä–∞—ó–Ω—Å—å–∫—É –º–æ–≤—É, —Ä–æ–∑–ø—ñ–∑–Ω–∞—î —Ñ–æ—Ä–º–∞—Ç–∏ –¥–∞—Ç, –Ω–æ–º–µ—Ä–∏ –∑–∞–≤–¥–∞–Ω—å —Ç–∞ –≥–µ–Ω–µ—Ä—É—î —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –¥–ª—è API.

üìä **–†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞–≤—á–∞–Ω–Ω—è:** Loss –∑–Ω–∏–∑–∏–≤—Å—è –∑ 1.64 –¥–æ 0.039 –∑–∞ 18 –µ–ø–æ—Ö, —â–æ –≤–∫–∞–∑—É—î –Ω–∞ –≤—ñ–¥–º—ñ–Ω–Ω–µ –∑–∞—Å–≤–æ—î–Ω–Ω—è –ø–∞—Ç–µ—Ä–Ω—ñ–≤.
""")