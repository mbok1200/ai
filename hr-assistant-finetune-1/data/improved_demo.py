import torch
import streamlit as st
import json
import random
import re
from peft import PeftModel
from transformers import AutoTokenizer, AutoModelForCausalLM

# --- –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è ---
base_model_name = "google/gemma-2-2b"
lora_path = "/content/drive/MyDrive/lora_hr_assistant_v2"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

@st.cache_resource
def load_model():
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∑ –∫–µ—à—É–≤–∞–Ω–Ω—è–º"""
    try:
        tokenizer = AutoTokenizer.from_pretrained(base_model_name, use_fast=True)
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token

        base_model = AutoModelForCausalLM.from_pretrained(
            base_model_name,
            torch_dtype=torch.float16,
            attn_implementation='eager'
        )
        
        model = PeftModel.from_pretrained(base_model, lora_path)
        model = model.merge_and_unload()
        model.to(device)
        model.eval()
        
        return tokenizer, model
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ: {e}")
        return None, None

def build_prompt(input_text: str) -> str:
    """–°—Ç–≤–æ—Ä—é—î –ø—Ä–æ–º–ø—Ç —É —Ñ–æ—Ä–º–∞—Ç—ñ –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è –∫—Ä–∞—â–æ—ó –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó JSON"""
    system_prompt = """–¢–∏ HR-–∞—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ —Å–∏—Å—Ç–µ–º–æ—é Redmine. –¢–≤–æ—è –º–µ—Ç–∞:
‚Ä¢ –†–æ–∑—É–º—ñ—Ç–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ –∑–∞–ø–∏—Ç–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
‚Ä¢ –ì–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –ø—Ä–∏—Ä–æ–¥–Ω—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é
‚Ä¢ –í–∏–∑–Ω–∞—á–∞—Ç–∏ –ø–æ—Ç—Ä—ñ–±–Ω—É —Ñ—É–Ω–∫—Ü—ñ—é —Ç–∞ —ó—ó –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
‚Ä¢ –ù–∞–¥–∞–≤–∞—Ç–∏ –∫–æ—Ä–∏—Å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é

–ë—É–¥—å –≤–≤—ñ—á–ª–∏–≤–∏–º, –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–º —Ç–∞ –∫–æ—Ä–∏—Å–Ω–∏–º."""

    return f"""{system_prompt}

–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á: {input_text}

–ê—Å–∏—Å—Ç–µ–Ω—Ç:"""

def generate_response(tokenizer, model, prompt: str, max_new_tokens: int = 300, temperature: float = 0.3):
    """–ì–µ–Ω–µ—Ä—É—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å –º–æ–¥–µ–ª—ñ –∑ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è JSON"""
    if tokenizer is None or model is None:
        return "–ü–æ–º–∏–ª–∫–∞: –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞"
    
    try:
        inputs = tokenizer(prompt, return_tensors="pt").to(device)
        
        with torch.no_grad():
            output_ids = model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                do_sample=True,
                temperature=temperature,
                top_p=0.95,
                repetition_penalty=1.05,
                pad_token_id=tokenizer.eos_token_id,
                eos_token_id=tokenizer.eos_token_id,
                early_stopping=True,
                no_repeat_ngram_size=3
            )
        
        generated_tokens = output_ids[0][inputs['input_ids'].shape[1]:]
        response = tokenizer.decode(generated_tokens, skip_special_tokens=True)
        
        return response.strip()
    except Exception as e:
        return f"–ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó: {str(e)}"

def extract_function_info(response_text: str):
    """–ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è JSON –∑ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ"""
    function_calls = []
    
    # –®—É–∫–∞—î–º–æ —Ä—ñ–∑–Ω—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ JSON –±–ª–æ–∫—ñ–≤
    json_patterns = [
        r'\{[^{}]*"function_call"[^{}]*\}',
        r'\{[^{}]*"name"[^{}]*"arguments"[^{}]*\}',
        r'Function Call:\s*\{[^{}]*\}',
        r'"function_call":\s*\{[^{}]*\}'
    ]
    
    for pattern in json_patterns:
        matches = re.findall(pattern, response_text, re.DOTALL | re.IGNORECASE)
        for match in matches:
            try:
                # –û—á–∏—â—É—î–º–æ —Ç–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ JSON
                clean_match = match.strip()
                if clean_match.startswith('Function Call:'):
                    clean_match = clean_match.replace('Function Call:', '').strip()
                
                func_data = json.loads(clean_match)
                if 'function_call' in func_data:
                    function_calls.append(func_data['function_call'])
                elif 'name' in func_data and 'arguments' in func_data:
                    function_calls.append(func_data)
            except json.JSONDecodeError:
                continue
    
    # –Ø–∫—â–æ JSON –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ, —Å–ø—Ä–æ–±—É—î–º–æ –≤–∏—Ç—è–≥–Ω—É—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ñ—É–Ω–∫—Ü—ñ—ó —Ç–µ–∫—Å—Ç–æ–º
    if not function_calls:
        text_function = extract_function_from_text(response_text)
        if text_function:
            function_calls.append(text_function)
    
    return function_calls
def extract_function_from_text(response_text: str):
    """–í–∏—Ç—è–≥—É—î —Ñ—É–Ω–∫—Ü—ñ—é –∑ —Ç–µ–∫—Å—Ç—É, —è–∫—â–æ JSON –Ω–µ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ"""
    response_lower = response_text.lower()
    
    # –†–æ–∑—à–∏—Ä–µ–Ω—ñ –ø–∞—Ç–µ—Ä–Ω–∏ –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ–π
    function_patterns = {
        'get_issue_by_date': ['–∑–∞–≤–¥–∞–Ω–Ω—è', '–¥–∞—Ç—É', '—Å—å–æ–≥–æ–¥–Ω—ñ', '–∑–∞–≤—Ç—Ä–∞', '—Ç–∏–∂–¥–µ–Ω—å', '–º—ñ—Å—è—Ü—å', '–Ω–∞ –¥–∞—Ç—É', 'my tasks', 'get_my_tasks'],
        'get_issue_by_id': ['#', '–Ω–æ–º–µ—Ä', '–∑–∞–≤–¥–∞–Ω–Ω—è', 'id', '–≤–∫–∞–∑–∞–Ω–∏–º id', '–∑–∞ id', '456789', '445432', '453213', 'calling_issue', 'get_issue'],
        'get_issue_by_name': ['user story', 'bug', '–Ω–∞–∑–≤–æ—é', '–∑ –Ω–∞–∑–≤–æ—é'],
        'get_issue_status': ['—Å—Ç–∞—Ç—É—Å', '—Å—Ç–∞–Ω'],
        'get_issue_hours': ['–≥–æ–¥–∏–Ω', '–≤–∏—Ç—Ä–∞—á–µ–Ω–æ', '—Å–∫—ñ–ª—å–∫–∏', 'getting_hours', 'get_assigned_hours'],
        'fill_issue_hours': ['–∑–∞–ø–æ–≤–Ω–∏—Ç–∏', '–≥–æ–¥–∏–Ω–∏', 'record time', '–∑–∞–ø—ñ—Å —á–∞—Å—É', 'fill_hours_for_days', 'filling_hours', 'updating_hours'],
        'get_user_status': ['–º—ñ–π —Å—Ç–∞—Ç—É—Å', '—Å—Ç–∞—Ç—É—Å –∞–∫–∞—É–Ω—Ç—É'],
        'set_user_status': ['—è –Ω–∞ —Ä–æ–±–æ—Ç—ñ', '—è –≤–¥–æ–º–∞'],
        'create_issue': ['—Å—Ç–≤–æ—Ä–∏', '—Å—Ç–≤–æ—Ä–∏—Ç–∏', 'create ticket', '–Ω–æ–≤–∏–π –Ω–∞–∫–ª–∞–¥', 'create_issue', 'creating_issue'],
        'assign_issue': ['–Ω–∞–∑–Ω–∞—á–∏—Ç–∏', '–ø—Ä–∏–∑–Ω–∞—á–∏—Ç–∏', 'assign', '–ø—Ä—ã–ø—ñ—Å—å—Ü–µ', 'assign_me_to_issue', 'assigning_me'],
        'get_wiki_info': ['wiki', '—ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è'],
        'resolve_issue': ['–≤—ã—Ä—ñ—à–∏—Ç–∏', 'resolve issue', '–∑–∞–∫—Ä–∏—Ç–∏']
    }
    for func_name, keywords in function_patterns.items():
        if any(keyword in response_lower for keyword in keywords):
            args = extract_arguments_from_response(response_text, func_name)
            return {
                "name": func_name,
                "arguments": args
            }

def extract_arguments_from_response(text: str, func_name: str):
    """–í–∏—Ç—è–≥—É—î –∞—Ä–≥—É–º–µ–Ω—Ç–∏ –∑ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —â–æ –º—ñ—Å—Ç–∏—Ç—å '–í–∏–∫–ª–∏–∫ —Ñ—É–Ω–∫—Ü—ñ—ó:'"""
    args = {}
    
    # –®—É–∫–∞—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –ø—ñ—Å–ª—è –Ω–∞–∑–≤–∏ —Ñ—É–Ω–∫—Ü—ñ—ó
    if 'params:' in text.lower():
        params_match = re.search(r"params:\s*['\"]([^'\"]+)['\"]", text)
        if params_match:
            args['value_1'] = params_match.group(1)
    
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏–π –ø–æ—à—É–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    param_patterns = [
        r"–ø–∞—Ä–∞–º–µ—Ç—Ä:\s*['\"]([^'\"]+)['\"]",
        r"ID[:\s]+['\"]?(\d+)['\"]?",
        r"#(\d+)",
        r"(\d{5,6})"
    ]
    
    for pattern in param_patterns:
        match = re.search(pattern, text)
        if match:
            args['value_1'] = match.group(1)
            break
    
    return args

def extract_arguments_from_text(text: str, func_name: str):
    """–í–∏—Ç—è–≥—É—î –∞—Ä–≥—É–º–µ–Ω—Ç–∏ –∑ —Ç–µ–∫—Å—Ç—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ç–∏–ø—É —Ñ—É–Ω–∫—Ü—ñ—ó"""
    args = {}
    text_lower = text.lower()
    
    if func_name == 'get_issue_by_date':
        if '—Å—å–æ–≥–æ–¥–Ω—ñ' in text_lower or 'today' in text_lower:
            args['value_1'] = 'today'
        elif '–∑–∞–≤—Ç—Ä–∞' in text_lower or 'tomorrow' in text_lower:
            args['value_1'] = 'tomorrow'
        elif '—Ç–∏–∂–¥–µ–Ω—å' in text_lower or 'week' in text_lower:
            args['value_1'] = 'week'
        elif '–º—ñ—Å—è—Ü—å' in text_lower or 'month' in text_lower:
            args['value_1'] = 'month'
        else:
            # –®—É–∫–∞—î–º–æ –¥–∞—Ç–∏ —É —Ñ–æ—Ä–º–∞—Ç—ñ 23.04 –∞–±–æ 23.04.2025
            date_match = re.search(r'\d{1,2}\.\d{1,2}\.?\d{0,4}', text)
            if date_match:
                args['value_1'] = date_match.group()
            else:
                args['value_1'] = 'all'  # –ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –≤—Å—ñ –∑–∞–≤–¥–∞–Ω–Ω—è
    
    elif func_name in ['get_issue_by_id', 'get_issue_status', 'get_issue_hours']:
        # –†–æ–∑—à–∏—Ä–µ–Ω–∏–π –ø–æ—à—É–∫ –Ω–æ–º–µ—Ä—ñ–≤ –∑–∞–≤–¥–∞–Ω—å
        id_patterns = [
            r"['\"](\d{5,6})['\"]",  # –£ –ª–∞–ø–∫–∞—Ö
            r"#(\d{5,6})",           # –ó —Ä–µ—à—ñ—Ç–∫–æ—é
            r"ID[:\s]+(\d{5,6})",    # –ü—ñ—Å–ª—è ID:
            r"(\d{5,6})"             # –ü—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ
        ]
        
        for pattern in id_patterns:
            id_match = re.search(pattern, text)
            if id_match:
                args['value_1'] = id_match.group(1)
                break
    
    elif func_name == 'get_issue_by_name':
        # –®—É–∫–∞—î–º–æ User Story, Bug –∞–±–æ —ñ–Ω—à—ñ –Ω–∞–∑–≤–∏
        name_patterns = [
            r"(User Story \d+)",
            r"(Bug \d+)",
            r"–∑ –Ω–∞–∑–≤–æ—é\s+['\"]([^'\"]+)['\"]",
            r"–Ω–∞–∑–≤–æ—é\s+['\"]([^'\"]+)['\"]"
        ]
        
        for pattern in name_patterns:
            name_match = re.search(pattern, text)
            if name_match:
                args['value_1'] = name_match.group(1)
                break
    
    elif func_name == 'fill_issue_hours':
        # –®—É–∫–∞—î–º–æ –∑–∞–≤–¥–∞–Ω–Ω—è —Ç–∞ –≥–æ–¥–∏–Ω–∏
        id_match = re.search(r'#?(\d{5,6})', text)
        hours_match = re.search(r'(\d+)\s*–≥–æ–¥–∏–Ω', text)
        if id_match:
            args['value_1'] = f"#{id_match.group(1)}"
        if hours_match:
            args['value_2'] = hours_match.group(1)
            args['value_3'] = 'today'
    
    elif func_name == 'set_user_status':
        if '–Ω–∞ —Ä–æ–±–æ—Ç—ñ' in text_lower or 'on_work' in text_lower:
            args['value_1'] = 'on_work'
        elif '–≤–¥–æ–º–∞' in text_lower or 'off_work' in text_lower:
            args['value_1'] = 'off_work'
    
    elif func_name == 'create_issue':
        # –®—É–∫–∞—î–º–æ –Ω–∞–∑–≤—É –Ω–æ–≤–æ–≥–æ –∑–∞–≤–¥–∞–Ω–Ω—è
        title_match = re.search(r"–Ω–∞–∑–≤–æ—é\s+['\"]([^'\"]+)['\"]", text)
        if title_match:
            args['value_1'] = title_match.group(1)
        else:
            args['value_1'] = '–ù–æ–≤–µ –∑–∞–≤–¥–∞–Ω–Ω—è'
    
    elif func_name == 'assign_issue':
        # –®—É–∫–∞—î–º–æ –∑–∞–≤–¥–∞–Ω–Ω—è —Ç–∞ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        id_match = re.search(r'#?(\d{5,6})', text)
        user_match = re.search(r'–Ω–∞–∑–Ω–∞—á–∏—Ç–∏\s+(\w+)', text)
        if id_match:
            args['value_1'] = f"#{id_match.group(1)}"
        if user_match:
            args['value_2'] = user_match.group(1)
    
    return args

def get_real_examples_from_dataset():
    """–ü–æ–≤–µ—Ä—Ç–∞—î —Ä–µ–∞–ª—å–Ω—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ –∑ –¥–∞—Ç–∞—Å–µ—Ç—É"""
    return [
        "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è",
        "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ —Å—å–æ–≥–æ–¥–Ω—ñ", 
        "—à–æ —Ç–∞–º –≤ –º–µ–Ω–µ –ø–æ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ –∑–∞–≤—Ç—Ä–∞",
        "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ —Ç–∏–∂–¥–µ–Ω—å",
        "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ –º—ñ—Å—è—Ü—å",
        "—â–æ –ø–æ –∑–∞–≤–¥–∞–Ω–Ω—è–º –Ω–∞ —Ä—ñ–∫",
        "—â–æ –≤ –º–µ–Ω–µ –∑–∞ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ 23.04",
        "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ 23.04.2025",
        "—â–æ –∑–∞ –∑–∞–≤–¥–∞–Ω–Ω—è #33456",
        "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è #33456",
        "#33456 —à–æ —Ç–∞–º –ø–æ –∑–∞–≤–¥–∞–Ω–Ω—é",
        "Bug 453465",
        "—â–æ –∑–∞ —Ç–∞—Å–∫–∞ Bug 453465",
        "User Story 453780",
        "—â–æ –∑–∞ User Story 453799",
        "—Å—Ç–∞—Ç—É—Å –∑–∞–≤–¥–∞–Ω–Ω—è 453799",
        "User Story 453759 —Å—Ç–∞—Ç—É—Å –∑–∞–≤–¥–∞–Ω–Ω—è",
        "#453799 —è–∫–∏–π —Å—Ç–∞—Ç—É—Å",
        "–°–∫—ñ–ª—å–∫–∏ –≥–æ–¥–∏–Ω –≤–∏—Ç—Ä–∞—á–µ–Ω–æ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è 453799",
        "#453799 —Å–∫—ñ–ª—å–∫–∏ –≥–æ–¥–∏–Ω –≤–∏—Ç—Ä–∞—á–µ–Ω–æ",
        "User Story 453759 —Å–∫—ñ–ª—å–∫–∏ –≥–æ–¥–∏–Ω –≤–∏—Ç—Ä–∞—á–µ–Ω–æ",
        "–∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –≥–æ–¥–∏–Ω–∏",
        "–∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –≥–æ–¥–∏–Ω–∏ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è #453799 2 –≥–æ–¥–∏–Ω–∏",
        "–∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –≥–æ–¥–∏–Ω–∏ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è User Story 453759 3 –≥–æ–¥–∏–Ω–∏",
        "–º—ñ–π —Å—Ç–∞—Ç—É—Å",
        "—Å—Ç–∞—Ç—É—Å –º–æ–≥–æ –∞–∫–∞—É–Ω—Ç—É",
        "—è –Ω–∞ —Ä–æ–±–æ—Ç—ñ",
        "—è –≤–¥–æ–º–∞",
        "—Å—Ç–≤–æ—Ä–∏ –∑–∞–≤–¥–∞–Ω–Ω—è",
        "—Å—Ç–≤–æ—Ä–∏ –∑–∞–≤–¥–∞–Ω–Ω—è –∑ –Ω–∞–∑–≤–æ—é '–ù–æ–≤–∏–π –ø—Ä–æ–µ–∫—Ç' —ñ –æ–ø–∏—Å–æ–º '–û–ø–∏—Å –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç—É'",
        "#453799 –Ω–∞–∑–Ω–∞—á–∏—Ç–∏ Yuri",
        "User Story 434256 –Ω–∞–∑–Ω–∞—á–∏—Ç–∏ Yuri",
        "wiki —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ø—Ä–æ–µ–∫—Ç"
    ]

def suggest_similar_examples(input_text: str):
    """–ü—Ä–æ–ø–æ–Ω—É—î —Å—Ö–æ–∂—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ –∑ –¥–∞—Ç–∞—Å–µ—Ç—É"""
    text_lower = input_text.lower()
    
    suggestions = []
    if '–∑–∞–≤–¥–∞–Ω–Ω—è' in text_lower:
        suggestions.extend([
            "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ —Å—å–æ–≥–æ–¥–Ω—ñ",
            "—â–æ –∑–∞ –∑–∞–≤–¥–∞–Ω–Ω—è #33456",
            "User Story 453780"
        ])
    if '—Å—Ç–∞—Ç—É—Å' in text_lower:
        suggestions.extend([
            "—Å—Ç–∞—Ç—É—Å –∑–∞–≤–¥–∞–Ω–Ω—è 453799",
            "–º—ñ–π —Å—Ç–∞—Ç—É—Å"
        ])
    if '–≥–æ–¥–∏–Ω' in text_lower:
        suggestions.extend([
            "–∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –≥–æ–¥–∏–Ω–∏ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è #453799 2 –≥–æ–¥–∏–Ω–∏",
            "–°–∫—ñ–ª—å–∫–∏ –≥–æ–¥–∏–Ω –≤–∏—Ç—Ä–∞—á–µ–Ω–æ –Ω–∞ –∑–∞–≤–¥–∞–Ω–Ω—è 453799"
        ])
    
    return list(set(suggestions))

def handle_special_cases(input_text: str, response: str, function_calls: list):
    """–û–±—Ä–æ–±–ª—è—î —Å–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ –≤–∏–ø–∞–¥–∫–∏, –∫–æ–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∑–≥–µ–Ω–µ—Ä—É–≤–∞–ª–∞ JSON"""
    input_lower = input_text.lower()
    response_lower = response.lower()
    
    # –í–∏–ø–∞–¥–æ–∫ "—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è"
    if '—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è' in input_lower and not function_calls:
        # –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞ –¥–∞—Ç–∞, —Ü–µ –∑–∞–≥–∞–ª—å–Ω–∏–π –∑–∞–ø–∏—Ç –≤—Å—ñ—Ö –∑–∞–≤–¥–∞–Ω—å
        if not any(word in input_lower for word in ['—Å—å–æ–≥–æ–¥–Ω—ñ', '–∑–∞–≤—Ç—Ä–∞', '—Ç–∏–∂–¥–µ–Ω—å', '–º—ñ—Å—è—Ü—å']):
            return [{
                "name": "get_issue_by_date",
                "arguments": {"value_1": "all"}
            }]
    
    # –í–∏–ø–∞–¥–æ–∫ –ø–æ—à—É–∫—É –∑–∞ ID –∑ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    if '–≤–∏–∫–ª–∏–∫ —Ñ—É–Ω–∫—Ü—ñ—ó' in response_lower and 'get_issue_by_id' in response_lower:
        id_match = re.search(r"['\"](\d{5,6})['\"]", response)
        if id_match:
            return [{
                "name": "get_issue_by_id", 
                "arguments": {"value_1": id_match.group(1)}
            }]
    
    # –í–∏–ø–∞–¥–æ–∫, –∫–æ–ª–∏ –∑–≥–∞–¥—É—î—Ç—å—Å—è "–∑–∞–≤–¥–∞–Ω–Ω—è" –∞–ª–µ —Ñ—É–Ω–∫—Ü—ñ—è –Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–∞
    if '–∑–∞–≤–¥–∞–Ω–Ω—è' in input_lower and not function_calls:
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î –≤ –∑–∞–ø–∏—Ç—ñ –Ω–æ–º–µ—Ä –∑–∞–≤–¥–∞–Ω–Ω—è
        id_match = re.search(r'#?(\d{5,6})', input_text)
        if id_match:
            return [{
                "name": "get_issue_by_id",
                "arguments": {"value_1": id_match.group(1)}
            }]
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î User Story –∞–±–æ Bug
        name_match = re.search(r'(User Story \d+|Bug \d+)', input_text, re.IGNORECASE)
        if name_match:
            return [{
                "name": "get_issue_by_name",
                "arguments": {"value_1": name_match.group(1)}
            }]
    
    # –í–∏–ø–∞–¥–æ–∫ —Å—Ç–∞—Ç—É—Å—É
    if '—Å—Ç–∞—Ç—É—Å' in input_lower and not function_calls:
        if '–º—ñ–π' in input_lower or '–∞–∫–∞—É–Ω—Ç' in input_lower:
            return [{
                "name": "get_user_status",
                "arguments": {}
            }]
        else:
            id_match = re.search(r'#?(\d{5,6})', input_text)
            if id_match:
                return [{
                    "name": "get_issue_status",
                    "arguments": {"value_1": id_match.group(1)}
                }]
    
    # –í–∏–ø–∞–¥–æ–∫ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å—Ç–∞—Ç—É—Å—É
    if ('—è –Ω–∞ —Ä–æ–±–æ—Ç—ñ' in input_lower or '—è –≤–¥–æ–º–∞' in input_lower) and not function_calls:
        status = 'on_work' if '–Ω–∞ —Ä–æ–±–æ—Ç—ñ' in input_lower else 'off_work'
        return [{
            "name": "set_user_status",
            "arguments": {"value_1": status}
        }]
    
    # –í–∏–ø–∞–¥–æ–∫ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑–∞–≤–¥–∞–Ω–Ω—è
    if ('—Å—Ç–≤–æ—Ä–∏' in input_lower or '—Å—Ç–≤–æ—Ä–∏—Ç–∏' in input_lower) and '–∑–∞–≤–¥–∞–Ω–Ω—è' in input_lower and not function_calls:
        title_match = re.search(r"–Ω–∞–∑–≤–æ—é\s+['\"]([^'\"]+)['\"]", input_text)
        title = title_match.group(1) if title_match else '–ù–æ–≤–µ –∑–∞–≤–¥–∞–Ω–Ω—è'
        return [{
            "name": "create_issue",
            "arguments": {"value_1": title}
        }]
    
    # –í–∏–ø–∞–¥–æ–∫ –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è
    if ('–Ω–∞–∑–Ω–∞—á–∏—Ç–∏' in input_lower or '–ø—Ä–∏–∑–Ω–∞—á–∏—Ç–∏' in input_lower) and not function_calls:
        id_match = re.search(r'#?(\d{5,6})', input_text)
        user_match = re.search(r'(–Ω–∞–∑–Ω–∞—á–∏—Ç–∏|–ø—Ä–∏–∑–Ω–∞—á–∏—Ç–∏)\s+(\w+)', input_text, re.IGNORECASE)
        if id_match and user_match:
            return [{
                "name": "assign_issue",
                "arguments": {
                    "value_1": f"#{id_match.group(1)}",
                    "value_2": user_match.group(2)
                }
            }]
    
    # –í–∏–ø–∞–¥–æ–∫ wiki
    if 'wiki' in input_lower and not function_calls:
        return [{
            "name": "get_wiki_info",
            "arguments": {"value_1": "–ø—Ä–æ–µ–∫—Ç"}
        }]
    
    # –í–∏–ø–∞–¥–æ–∫ –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –≥–æ–¥–∏–Ω
    if ('–∑–∞–ø–æ–≤–Ω–∏—Ç–∏' in input_lower and '–≥–æ–¥–∏–Ω' in input_lower) and not function_calls:
        id_match = re.search(r'#?(\d{5,6})', input_text)
        hours_match = re.search(r'(\d+)\s*–≥–æ–¥–∏–Ω', input_text)
        if id_match:
            args = {"value_1": f"#{id_match.group(1)}"}
            if hours_match:
                args["value_2"] = hours_match.group(1)
                args["value_3"] = "today"
            return [{
                "name": "fill_issue_hours",
                "arguments": args
            }]
    
    # –í–∏–ø–∞–¥–æ–∫ –ø–µ—Ä–µ–≥–ª—è–¥—É –≤–∏—Ç—Ä–∞—á–µ–Ω–∏—Ö –≥–æ–¥–∏–Ω
    if ('—Å–∫—ñ–ª—å–∫–∏' in input_lower and '–≥–æ–¥–∏–Ω' in input_lower) and not function_calls:
        id_match = re.search(r'#?(\d{5,6})', input_text)
        if id_match:
            return [{
                "name": "get_issue_hours",
                "arguments": {"value_1": id_match.group(1)}
            }]
    
    return function_calls

# --- Streamlit UI ---
st.set_page_config(
    page_title="HR Assistant - –ü–æ–∫—Ä–∞—â–µ–Ω–∞ –≤–µ—Ä—Å—ñ—è",
    page_icon="ü§ñ",
    layout="wide"
)

st.title("ü§ñ HR Assistant - –ù–∞–≤—á–µ–Ω–∞ –º–æ–¥–µ–ª—å (Loss: 1.64 ‚Üí 0.039)")
st.markdown("*–ü—Ä–æ—Ç–µ—Å—Ç—É–π—Ç–µ –º–æ–¥–µ–ª—å –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–æ—é –≥–µ–Ω–µ—Ä–∞—Ü—ñ—î—é JSON*")

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
with st.spinner("‚è≥ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ..."):
    tokenizer, model = load_model()

if tokenizer is None or model is None:
    st.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å")
    st.stop()

st.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ —Ç–∞ –≥–æ—Ç–æ–≤–∞ –¥–æ —Ä–æ–±–æ—Ç–∏!")

# –ë—ñ—á–Ω–∞ –ø–∞–Ω–µ–ª—å
st.sidebar.header("üìã –ü—Ä–∏–∫–ª–∞–¥–∏ –∑ –¥–∞—Ç–∞—Å–µ—Ç—É")
real_examples = get_real_examples_from_dataset()
selected_example = st.sidebar.selectbox(
    "–û–±–µ—Ä—ñ—Ç—å –ø—Ä–∏–∫–ª–∞–¥:",
    [""] + real_examples
)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
st.sidebar.markdown("---")
st.sidebar.markdown("### üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞–≤—á–∞–Ω–Ω—è")
st.sidebar.metric("Train Loss", "0.039", "-97.6%")
st.sidebar.metric("Eval Loss", "0.231", "-59.2%")
st.sidebar.metric("–ï–ø–æ—Ö", "18", "126 –∫—Ä–æ–∫—ñ–≤")

# –ü–æ–∫–∞–∑—É—î–º–æ —Ñ—É–Ω–∫—Ü—ñ—ó –∑ –¥–∞—Ç–∞—Å–µ—Ç—É
st.sidebar.markdown("### üîß –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó:")
functions_info = {
    "üìÖ get_issue_by_date": "today, tomorrow, week, month",
    "üîç get_issue_by_id": "#33456, 453799",
    "üìù get_issue_by_name": "User Story, Bug",
    "üìä get_issue_status": "—Å—Ç–∞—Ç—É—Å –∑–∞–≤–¥–∞–Ω–Ω—è",
    "‚è±Ô∏è get_issue_hours": "–≤–∏—Ç—Ä–∞—á–µ–Ω—ñ –≥–æ–¥–∏–Ω–∏",
    "‚úèÔ∏è fill_issue_hours": "–∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –≥–æ–¥–∏–Ω–∏",
    "üë§ get_user_status": "–º—ñ–π —Å—Ç–∞—Ç—É—Å",
    "üîÑ set_user_status": "–Ω–∞ —Ä–æ–±–æ—Ç—ñ, –≤–¥–æ–º–∞",
    "‚ûï create_issue": "—Å—Ç–≤–æ—Ä–∏—Ç–∏ –∑–∞–≤–¥–∞–Ω–Ω—è",
    "üë• assign_issue": "–ø—Ä–∏–∑–Ω–∞—á–∏—Ç–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É",
    "üìö get_wiki_info": "wiki —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è"
}

for func, desc in functions_info.items():
    st.sidebar.write(f"**{func}**: {desc}")

# –û—Å–Ω–æ–≤–Ω–∏–π —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("üì• –í–≤–µ–¥—ñ—Ç—å –∑–∞–ø–∏—Ç")
    
    input_text = st.text_area(
        "–ó–∞–ø–∏—Ç —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é:",
        value=selected_example,
        placeholder="–ù–∞–ø—Ä–∏–∫–ª–∞–¥: —è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ —Å—å–æ–≥–æ–¥–Ω—ñ",
        height=150
    )
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
    col1_1, col1_2 = st.columns(2)
    with col1_1:
        max_tokens = st.slider("–ú–∞–∫—Å. —Ç–æ–∫–µ–Ω—ñ–≤:", 50, 512, 250)
    with col1_2:
        temperature = st.slider("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:", 0.1, 1.0, 0.3, 0.1)
    
    # –û–ø—Ü—ñ—ó –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
    st.markdown("**üîß –û–ø—Ü—ñ—ó –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó:**")
    force_json = st.checkbox("–ü—Ä–∏–º—É—Å–æ–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è JSON", value=True)
    analyze_text = st.checkbox("–ê–Ω–∞–ª—ñ–∑ —Ç–µ–∫—Å—Ç—É –ø—Ä–∏ –≤—ñ–¥—Å—É—Ç–Ω–æ—Å—Ç—ñ JSON", value=True)
    show_prompt = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç–∏ –ø—Ä–æ–º–ø—Ç", value=False)
    
    generate_button = st.button("üöÄ –ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å", type="primary", use_container_width=True)

with col2:
    st.subheader("üì§ –í—ñ–¥–ø–æ–≤—ñ–¥—å HR Assistant")
    
    if generate_button:
        if not input_text.strip():
            st.warning("‚ö†Ô∏è –í–≤–µ–¥—ñ—Ç—å —Ç–µ–∫—Å—Ç –∑–∞–ø–∏—Ç—É")
        else:
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –º–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞
            if tokenizer is None or model is None:
                st.error("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞. –ü–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Å—Ç–æ—Ä—ñ–Ω–∫—É.")
            else:
                with st.spinner("ü§ñ –ú–æ–¥–µ–ª—å –∞–Ω–∞–ª—ñ–∑—É—î –∑–∞–ø–∏—Ç..."):
                    try:
                        # –ú–æ–¥–∏—Ñ—ñ–∫—É—î–º–æ –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫—Ä–∞—â–æ—ó JSON –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
                        base_prompt = build_prompt(input_text)
                        
                        if show_prompt:
                            with st.expander("üîç –ü–æ–∫–∞–∑–∞—Ç–∏ –ø—Ä–æ–º–ø—Ç"):
                                st.code(base_prompt)
                        
                        if force_json:
                            enhanced_prompt = base_prompt + "\n\nFunction Call:\n{"
                            response = generate_response(tokenizer, model, enhanced_prompt, max_tokens, temperature)
                            if not response.strip().startswith('{'):
                                response = "{\n" + response
                        else:
                            response = generate_response(tokenizer, model, base_prompt, max_tokens, temperature)
                        
                        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î –ø–æ–º–∏–ª–∫–∞ –≤ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
                        if response.startswith("–ü–æ–º–∏–ª–∫–∞"):
                            st.error(f"‚ùå {response}")
                        else:
                            # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
                            st.text_area(
                                "–ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å:",
                                value=response,
                                height=150,
                                disabled=True
                            )
                            
                            # –ê–Ω–∞–ª—ñ–∑ —Ñ—É–Ω–∫—Ü—ñ–π
                            function_calls = extract_function_info(response)
                            if function_calls:
                                st.subheader("‚öôÔ∏è –í–∏—è–≤–ª–µ–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó")
                                for func in function_calls:
                                    st.code(json.dumps(func, ensure_ascii=False, indent=2))
                            else:
                                st.warning("üîç –§—É–Ω–∫—Ü—ñ—ó –Ω–µ –≤–∏—è–≤–ª–µ–Ω–æ –≤ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ")
                                
                                if analyze_text and any(keyword in response.lower() for keyword in ['–∑–∞–≤–¥–∞–Ω–Ω—è', '—Å—Ç–∞—Ç—É—Å', '–≥–æ–¥–∏–Ω–∏', '—Å—Ç–≤–æ—Ä–∏']):
                                    st.info("üí° –ú–æ–¥–µ–ª—å —Ä–æ–∑–ø—ñ–∑–Ω–∞–ª–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç. –°–ø—Ä–æ–±—É–π—Ç–µ:")
                                    st.markdown("""
                                    - –£–≤—ñ–º–∫–Ω—ñ—Ç—å '–ü—Ä–∏–º—É—Å–æ–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è JSON'
                                    - –ó–º–µ–Ω—à—ñ—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–æ 0.1-0.3
                                    - –ê–±–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ —Ç–æ—á–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥ –∑ –¥–∞—Ç–∞—Å–µ—Ç—É
                                    """)
                                    
                                    # –ü—Ä–æ–ø–æ–Ω—É—î–º–æ —Å—Ö–æ–∂—ñ –ø—Ä–∏–∫–ª–∞–¥–∏
                                    suggestions = []
                                    if suggestions:
                                        st.markdown("**üéØ –°—Ö–æ–∂—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ –∑ –¥–∞—Ç–∞—Å–µ—Ç—É:**")
                                        for suggestion in suggestions[:3]:
                                            st.code(suggestion)
                    
                    except Exception as e:
                        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó: {str(e)}")
                        st.info("üí° –°–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–æ—Ä—ñ–Ω–∫—É –∞–±–æ –∑–º–µ–Ω—à–∏—Ç–∏ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–∫–µ–Ω—ñ–≤")

# –î–æ–¥–∞—Ç–∫–æ–≤–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –º–æ–¥–µ–ª—å
st.markdown("---")
st.subheader("üìä –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –º–æ–¥–µ–ª—å")

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("**üéØ –ù–∞–≤—á–∞–Ω–Ω—è:**")
    st.write("‚Ä¢ –î–∞—Ç–∞—Å–µ—Ç: 58 –ø—Ä–∏–∫–ª–∞–¥—ñ–≤")
    st.write("‚Ä¢ Train/Eval: 52/6")
    st.write("‚Ä¢ –ï–ø–æ—Ö: 18 (126 –∫—Ä–æ–∫—ñ–≤)")
    st.write("‚Ä¢ Final Loss: 0.039")

with col2:
    st.markdown("**‚öôÔ∏è –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞:**")
    st.write("‚Ä¢ –ë–∞–∑–∞: Gemma-2-2b")
    st.write("‚Ä¢ LoRA –∞–¥–∞–ø—Ç–µ—Ä")
    st.write("‚Ä¢ –ü–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤: 20.7M")
    st.write("‚Ä¢ Dtype: float16")

with col3:
    st.markdown("**üîß –§—É–Ω–∫—Ü—ñ—ó:**")
    st.write("‚Ä¢ 11 —Ç–∏–ø—ñ–≤ —Ñ—É–Ω–∫—Ü—ñ–π")
    st.write("‚Ä¢ JSON –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è")
    st.write("‚Ä¢ –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –º–æ–≤–∞")
    st.write("‚Ä¢ Redmine API")

# –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
with st.expander("üìñ –ü—Ä–∏–∫–ª–∞–¥ —Ä–æ–±–æ—Ç–∏ –∑ –º–æ–¥–µ–ª–ª—é"):
    st.markdown("""
    **–ó–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞:** `—è–∫—ñ –≤ –º–µ–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ —Å—å–æ–≥–æ–¥–Ω—ñ`
    
    **–í—ñ–¥–ø–æ–≤—ñ–¥—å –º–æ–¥–µ–ª—ñ:**
    ```
    –ü–µ—Ä–µ–≤—ñ—Ä—è—é –∑–∞–≤–¥–∞–Ω–Ω—è –∑–∞ –≤–∫–∞–∑–∞–Ω–æ—é –¥–∞—Ç–æ—é.
    –í–∏–∫–ª–∏–∫ —Ñ—É–Ω–∫—Ü—ñ—ó: get_issue_by_date, –ø–∞—Ä–∞–º–µ—Ç—Ä: 'today'
    ```
    
    **–í–∏—è–≤–ª–µ–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è:**
    ```json
    {
        "name": "get_issue_by_date",
        "arguments": {
            "value_1": "today"
        }
    }
    ```
    
    **–ú–æ–∫–æ–≤–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å API:**
    üìÖ –ó–∞–≤–¥–∞–Ω–Ω—è –Ω–∞ today: #453231, #453232, #453233 (3 –∞–∫—Ç–∏–≤–Ω–∏—Ö –∑–∞–≤–¥–∞–Ω–Ω—è)
    """)

st.info("""
üéØ **–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ú–æ–¥–µ–ª—å —É—Å–ø—ñ—à–Ω–æ –Ω–∞–≤—á–∏–ª–∞—Å—å —Ä–æ–∑—É–º—ñ—Ç–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ –∑–∞–ø–∏—Ç–∏ —Ç–∞ –≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ –≤–∏–∫–ª–∏–∫–∏ —Ñ—É–Ω–∫—Ü—ñ–π –¥–ª—è Redmine API.
–§—ñ–Ω–∞–ª—å–Ω–∏–π loss 0.039 –ø–æ–∫–∞–∑—É—î –≤—ñ–¥–º—ñ–Ω–Ω—É –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü—ñ—é!
""")